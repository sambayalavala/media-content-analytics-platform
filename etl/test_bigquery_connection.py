# etl/test_bigquery_connection.py
from google.cloud import bigquery
from google.oauth2 import service_account

# âœ… Configuration
GCP_PROJECT_ID = "mcap-project-477416"
GCP_CREDENTIALS_PATH = r"C:\Users\samba\OneDrive\Desktop\Media_Content_Analytics_Platform\config\mcap-project-477416-81b2e0d3de01.json"
BQ_DATASET = "yt_warehouse"

# âœ… Create BigQuery client using service account
try:
    credentials = service_account.Credentials.from_service_account_file(GCP_CREDENTIALS_PATH)
    client = bigquery.Client(credentials=credentials, project=GCP_PROJECT_ID)
    print(f"âœ… Successfully connected to BigQuery project: {GCP_PROJECT_ID}")
except Exception as e:
    print("âŒ Failed to connect to BigQuery:", e)
    exit(1)

# âœ… List datasets
print("\nğŸ“¦ Available Datasets in this project:")
datasets = list(client.list_datasets())
if datasets:
    for dataset in datasets:
        print(f" - {dataset.dataset_id}")
else:
    print("âš ï¸ No datasets found in this project.")

# âœ… Check if yt_warehouse dataset exists
dataset_ref = f"{GCP_PROJECT_ID}.{BQ_DATASET}"
try:
    dataset = client.get_dataset(dataset_ref)
    print(f"\nâœ… Dataset '{BQ_DATASET}' exists and is accessible.")
except Exception as e:
    print(f"âŒ Unable to access dataset '{BQ_DATASET}':", e)
    exit(1)

# âœ… List tables in dataset
print(f"\nğŸ“‹ Tables in dataset '{BQ_DATASET}':")
try:
    tables = list(client.list_tables(dataset_ref))
    if tables:
        for table in tables:
            print(f" - {table.table_id}")
    else:
        print("âš ï¸ No tables found in this dataset.")
except Exception as e:
    print("âŒ Error listing tables:", e)

print("\nğŸ¯ BigQuery connection test complete.")
